{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean   \n",
       "0    842302         M        17.99         10.38          122.80     1001.0  \\\n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean   \n",
       "0          0.11840           0.27760          0.3001              0.14710  \\\n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst   \n",
       "0  ...          17.33           184.60      2019.0            0.1622  \\\n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst   \n",
       "0             0.6656           0.7119                0.2654          0.4601  \\\n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis\n",
       "B    357\n",
       "M    212\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Dataset Info:\")\n",
    "print(data.info())\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      "id                           0\n",
      "diagnosis                    0\n",
      "radius_mean                  0\n",
      "texture_mean                 0\n",
      "perimeter_mean               0\n",
      "area_mean                    0\n",
      "smoothness_mean              0\n",
      "compactness_mean             0\n",
      "concavity_mean               0\n",
      "concave points_mean          0\n",
      "symmetry_mean                0\n",
      "fractal_dimension_mean       0\n",
      "radius_se                    0\n",
      "texture_se                   0\n",
      "perimeter_se                 0\n",
      "area_se                      0\n",
      "smoothness_se                0\n",
      "compactness_se               0\n",
      "concavity_se                 0\n",
      "concave points_se            0\n",
      "symmetry_se                  0\n",
      "fractal_dimension_se         0\n",
      "radius_worst                 0\n",
      "texture_worst                0\n",
      "perimeter_worst              0\n",
      "area_worst                   0\n",
      "smoothness_worst             0\n",
      "compactness_worst            0\n",
      "concavity_worst              0\n",
      "concave points_worst         0\n",
      "symmetry_worst               0\n",
      "fractal_dimension_worst      0\n",
      "Unnamed: 32                569\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Missing Values:\")\n",
    "print(data.isnull().sum())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " id                         0\n",
      "diagnosis                  0\n",
      "radius_mean                0\n",
      "texture_mean               0\n",
      "perimeter_mean             0\n",
      "area_mean                  0\n",
      "smoothness_mean            0\n",
      "compactness_mean           0\n",
      "concavity_mean             0\n",
      "concave points_mean        0\n",
      "symmetry_mean              0\n",
      "fractal_dimension_mean     0\n",
      "radius_se                  0\n",
      "texture_se                 0\n",
      "perimeter_se               0\n",
      "area_se                    0\n",
      "smoothness_se              0\n",
      "compactness_se             0\n",
      "concavity_se               0\n",
      "concave points_se          0\n",
      "symmetry_se                0\n",
      "fractal_dimension_se       0\n",
      "radius_worst               0\n",
      "texture_worst              0\n",
      "perimeter_worst            0\n",
      "area_worst                 0\n",
      "smoothness_worst           0\n",
      "compactness_worst          0\n",
      "concavity_worst            0\n",
      "concave points_worst       0\n",
      "symmetry_worst             0\n",
      "fractal_dimension_worst    0\n",
      "dtype: int64\n",
      "Cleaned Data:\n",
      "          id  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean   \n",
      "1    842517          1     2.204465     -0.282612        2.068351   2.454131  \\\n",
      "2  84300903          1     1.914972      0.595678        1.928754   2.024982   \n",
      "4  84358402          1     2.112354     -1.148284        2.174252   2.352950   \n",
      "5    843786          1    -0.466770     -0.805044       -0.354381  -0.507699   \n",
      "6    844359          1     1.441255      0.275153        1.428130   1.456271   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean   \n",
      "1        -0.806833         -0.392414        0.206957             0.826142  \\\n",
      "2         1.134031          1.588118        1.999878             2.601498   \n",
      "4         0.407963          0.927616        2.009614             1.875733   \n",
      "5         2.554936          1.834284        1.357347             1.155812   \n",
      "6        -0.034703          0.347544        0.625576             0.943925   \n",
      "\n",
      "   ...  radius_worst  texture_worst  perimeter_worst  area_worst   \n",
      "1  ...      2.215670      -0.307819         1.938870    2.509421  \\\n",
      "2  ...      1.871562       0.066720         1.716129    1.963460   \n",
      "4  ...      1.621963      -1.498573         1.705522    1.667270   \n",
      "5  ...     -0.091304      -0.247752        -0.019839   -0.174851   \n",
      "6  ...      1.704355       0.443027         1.740878    1.735792   \n",
      "\n",
      "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst   \n",
      "1         -0.333961          -0.355468         0.004135              1.365129  \\\n",
      "2          0.644786           1.540072         1.226375              2.345448   \n",
      "4          0.312202          -0.208860         0.931351              0.960963   \n",
      "5          2.293453           2.340040         1.724519              1.160466   \n",
      "6          0.635284           0.210246         0.804913              1.488959   \n",
      "\n",
      "   symmetry_worst  fractal_dimension_worst  \n",
      "1       -0.177083                 0.524615  \n",
      "2        1.561970                 0.424590  \n",
      "4       -0.954921                -0.325600  \n",
      "5        2.311596                 2.982183  \n",
      "6        0.453651                 0.153688  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if 'Unnamed: 32' in data.columns:\n",
    "    data = data.drop(columns=['Unnamed: 32'])\n",
    "\n",
    "\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)\n",
    "\n",
    "\n",
    "data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')  \n",
    "data.iloc[:, :] = imputer.fit_transform(data)\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "z_scores = np.abs(stats.zscore(data.iloc[:, 2:]))  \n",
    "outliers = (z_scores > 3).sum(axis=1)\n",
    "data = data[(outliers < 1)]  \n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data.iloc[:, 2:] = scaler.fit_transform(data.iloc[:, 2:])\n",
    "\n",
    "\n",
    "print(\"Cleaned Data:\\n\", data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (396, 30)\n",
      "X_test shape: (99, 30)\n",
      "y_train shape: (396,)\n",
      "y_test shape: (99,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = data.drop(columns=['id', 'diagnosis'])  \n",
    "y = data['diagnosis'] \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes (NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.9293\n",
      "Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94        66\n",
      "           1       0.84      0.97      0.90        33\n",
      "\n",
      "    accuracy                           0.93        99\n",
      "   macro avg       0.91      0.94      0.92        99\n",
      "weighted avg       0.94      0.93      0.93        99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "report_nb = classification_report(y_test, y_pred_nb)\n",
    "\n",
    "print(f\"Naive Bayes Accuracy: {accuracy_nb:.4f}\")\n",
    "print(\"Naive Bayes Classification Report:\")\n",
    "print(report_nb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted Multiple Radial Basis Function Support Vector Machine (WMRBF-SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WMRBF-SVM Accuracy: 0.9798\n",
      "WMRBF-SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        66\n",
      "           1       0.97      0.97      0.97        33\n",
      "\n",
      "    accuracy                           0.98        99\n",
      "   macro avg       0.98      0.98      0.98        99\n",
      "weighted avg       0.98      0.98      0.98        99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "wmrbf_svm_model = SVC(kernel='rbf', class_weight='balanced') \n",
    "\n",
    "\n",
    "wmrbf_svm_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_svm = wmrbf_svm_model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "report_svm = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "print(f\"WMRBF-SVM Accuracy: {accuracy_svm:.4f}\")\n",
    "print(\"WMRBF-SVM Classification Report:\")\n",
    "print(report_svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WALSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,200</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m30\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │     \u001b[38;5;34m16,200\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │        \u001b[38;5;34m101\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,301</span> (63.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,301\u001b[0m (63.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,301</span> (63.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,301\u001b[0m (63.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\ops\\nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.8663 - loss: 0.6189 - val_accuracy: 0.9231 - val_loss: 0.5107\n",
      "Epoch 2/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9443 - loss: 0.4878 - val_accuracy: 0.9231 - val_loss: 0.4064\n",
      "Epoch 3/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9603 - loss: 0.3717 - val_accuracy: 0.9231 - val_loss: 0.3274\n",
      "Epoch 4/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9736 - loss: 0.3029 - val_accuracy: 0.9341 - val_loss: 0.2707\n",
      "Epoch 5/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9665 - loss: 0.2482 - val_accuracy: 0.9451 - val_loss: 0.2292\n",
      "Epoch 6/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9663 - loss: 0.2125 - val_accuracy: 0.9560 - val_loss: 0.1992\n",
      "Epoch 7/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9651 - loss: 0.1856 - val_accuracy: 0.9560 - val_loss: 0.1767\n",
      "Epoch 8/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9717 - loss: 0.1543 - val_accuracy: 0.9560 - val_loss: 0.1594\n",
      "Epoch 9/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9805 - loss: 0.1256 - val_accuracy: 0.9560 - val_loss: 0.1454\n",
      "Epoch 10/10\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9642 - loss: 0.1281 - val_accuracy: 0.9670 - val_loss: 0.1357\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 196ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\ops\\nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (32, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "WALSTM Accuracy: 0.9737\n",
      "WALSTM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        72\n",
      "           1       0.98      0.95      0.96        42\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Attention, Concatenate\n",
    "\n",
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "\n",
    "if 'Unnamed: 32' in data.columns:\n",
    "    data = data.drop(columns=['Unnamed: 32'])\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "\n",
    "data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data.iloc[:, :] = imputer.fit_transform(data)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data.iloc[:, 2:] = scaler.fit_transform(data.iloc[:, 2:])\n",
    "\n",
    "\n",
    "X = data.drop(columns=['id', 'diagnosis'])\n",
    "y = data['diagnosis']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "X_train_reshaped = np.expand_dims(X_train, axis=1)\n",
    "X_test_reshaped = np.expand_dims(X_test, axis=1)\n",
    "\n",
    "\n",
    "input_layer = Input(shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]))\n",
    "\n",
    "\n",
    "lstm_out = LSTM(units=50, return_sequences=True)(input_layer)\n",
    "\n",
    "\n",
    "query = lstm_out\n",
    "value = lstm_out\n",
    "attention_out = Attention()([query, value])\n",
    "\n",
    "\n",
    "concat_out = Concatenate()([lstm_out, attention_out])\n",
    "\n",
    "\n",
    "dense_out = Dense(1, activation='sigmoid')(concat_out)\n",
    "\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=dense_out)\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "history = model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "\n",
    "y_pred_proba = model.predict(X_test_reshaped)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()  \n",
    "\n",
    "\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "assert y_test.shape == y_pred.shape, f\"Shape mismatch: y_test shape {y_test.shape}, y_pred shape {y_pred.shape}\"\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"WALSTM Accuracy: {accuracy:.4f}\")\n",
    "print(\"WALSTM Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy: 0.9117\n",
      "Decision Tree Accuracy: 0.9298\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        72\n",
      "           1       0.90      0.90      0.90        42\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.92      0.92      0.92       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "\n",
    "if 'Unnamed: 32' in data.columns:\n",
    "    data = data.drop(columns=['Unnamed: 32'])\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "\n",
    "data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data.iloc[:, :] = imputer.fit_transform(data)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data.iloc[:, 2:] = scaler.fit_transform(data.iloc[:, 2:])\n",
    "\n",
    "\n",
    "X = data.drop(columns=['id', 'diagnosis'])\n",
    "y = data['diagnosis']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "dt_model = DecisionTreeClassifier(criterion='gini', max_depth=None, random_state=42)\n",
    "\n",
    "\n",
    "cv_scores = cross_val_score(dt_model, X_train, y_train, cv=10)\n",
    "\n",
    "print(f\"Cross-Validation Accuracy: {cv_scores.mean():.4f}\")\n",
    "\n",
    "\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = dt_model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Decision Tree Accuracy: {accuracy:.4f}\")\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 72 candidates, totalling 720 fits\n",
      "Best parameters: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
      "Cross-Validation Accuracy (Decision Tree): 0.9316\n",
      "Decision Tree Accuracy: 0.9386\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        72\n",
      "           1       1.00      0.83      0.91        42\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.96      0.92      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "Random Forest Accuracy: 0.9737\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        72\n",
      "           1       1.00      0.93      0.96        42\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.98      0.96      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "\n",
    "if 'Unnamed: 32' in data.columns:\n",
    "    data = data.drop(columns=['Unnamed: 32'])\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data.iloc[:, :] = imputer.fit_transform(data)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data.iloc[:, 2:] = scaler.fit_transform(data.iloc[:, 2:])\n",
    "\n",
    "X = data.drop(columns=['id', 'diagnosis'])\n",
    "y = data['diagnosis']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=10, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "\n",
    "dt_model = DecisionTreeClassifier(**best_params, random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "cv_scores = cross_val_score(dt_model, X_train, y_train, cv=10)\n",
    "print(f\"Cross-Validation Accuracy (Decision Tree): {cv_scores.mean():.4f}\")\n",
    "\n",
    "\n",
    "y_pred = dt_model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f\"Decision Tree Accuracy: {accuracy:.4f}\")\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "rf_report = classification_report(y_test, rf_pred)\n",
    "\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(rf_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9737\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        72\n",
      "           1       0.98      0.95      0.96        42\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "K-Nearest Neighbors Accuracy: 0.9561\n",
      "K-Nearest Neighbors Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97        72\n",
      "           1       0.97      0.90      0.94        42\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "Support Vector Machine Accuracy: 0.9737\n",
      "Support Vector Machine Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        72\n",
      "           1       1.00      0.93      0.96        42\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.98      0.96      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Decision Tree Accuracy: 0.9298\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        72\n",
      "           1       0.90      0.90      0.90        42\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.92      0.92      0.92       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "Random Forest Accuracy: 0.9737\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        72\n",
      "           1       1.00      0.93      0.96        42\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.98      0.96      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Gradient Boosting Accuracy: 0.9649\n",
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97        72\n",
      "           1       1.00      0.90      0.95        42\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.95      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n",
      "Naive Bayes Accuracy: 0.9211\n",
      "Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94        72\n",
      "           1       0.92      0.86      0.89        42\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.92      0.91      0.91       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "\n",
      "Accuracy Comparison:\n",
      "Logistic Regression: 0.9737\n",
      "K-Nearest Neighbors: 0.9561\n",
      "Support Vector Machine: 0.9737\n",
      "Decision Tree: 0.9298\n",
      "Random Forest: 0.9737\n",
      "Gradient Boosting: 0.9649\n",
      "Naive Bayes: 0.9211\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "\n",
    "if 'Unnamed: 32' in data.columns:\n",
    "    data = data.drop(columns=['Unnamed: 32'])\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "\n",
    "data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data.iloc[:, :] = imputer.fit_transform(data)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data.iloc[:, 2:] = scaler.fit_transform(data.iloc[:, 2:])\n",
    "\n",
    "\n",
    "X = data.drop(columns=['id', 'diagnosis'])\n",
    "y = data['diagnosis']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Support Vector Machine\": SVC(kernel='rbf', random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "\n",
    "results = {}\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[name] = accuracy\n",
    "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"{name} Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "print(\"\\nAccuracy Comparison:\")\n",
    "for name, accuracy in results.items():\n",
    "    print(f\"{name}: {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
